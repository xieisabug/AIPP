use super::browser_pool::BrowserPool;
use super::super::browser::BrowserManager;
use super::super::engine_manager::SearchEngine;
use super::super::fingerprint::{FingerprintConfig, FingerprintManager, TimingConfig};
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::time::Duration;
use tauri::{AppHandle, Manager};
use tokio::process::Command as TokioCommand;
use tokio::time::sleep;
use tracing::{debug, info, trace, warn};

/// ========== è°ƒè¯•å¼€å…³ ==========
/// è®¾ç½®ä¸º true æ—¶ä¼šä¿å­˜è·å–åˆ°çš„HTMLåˆ° /tmp ç›®å½•
/// è°ƒè¯•å®Œæˆåè¯·è®¾ç½®ä¸º false
const DEBUG_SAVE_HTML: bool = false;
/// è°ƒè¯•HTMLä¿å­˜ç›®å½•
const DEBUG_HTML_DIR: &str = "~/tmp";

#[derive(Debug, Clone)]
pub struct FetchConfig {
    pub user_data_dir: Option<String>,
    pub proxy_server: Option<String>,
    pub headless: bool,
    pub user_agent: Option<String>,
    pub bypass_csp: bool,
    pub wait_selectors: Vec<String>,
    pub wait_timeout_ms: u64,
    pub wait_poll_ms: u64,
    /// Kagi ä¼šè¯é“¾æ¥ï¼Œä»…åœ¨ä½¿ç”¨ Kagi æœç´¢å¼•æ“æ—¶ç”Ÿæ•ˆ
    /// æ ¼å¼å¦‚ï¼šhttps://kagi.com/search?token=xxxxx
    pub kagi_session_url: Option<String>,
}

impl Default for FetchConfig {
    fn default() -> Self {
        Self {
            user_data_dir: None,
            proxy_server: None,
            headless: true,
            user_agent: None,
            bypass_csp: false,
            wait_selectors: vec![],
            wait_timeout_ms: 15000,
            wait_poll_ms: 250,
            kagi_session_url: None,
        }
    }
}

pub struct ContentFetcher {
    app_handle: AppHandle,
    config: FetchConfig,
    fingerprint_manager: FingerprintManager,
    timing_config: TimingConfig,
}

impl ContentFetcher {
    pub fn new(app_handle: AppHandle, config: FetchConfig) -> Self {
        let app_data_dir = app_handle
            .path()
            .app_data_dir()
            .unwrap_or_else(|_| std::env::current_dir().unwrap_or_default().join("data"));

        let fingerprint_manager = FingerprintManager::new(&app_data_dir);
        let timing_config = FingerprintManager::get_timing_config();

        Self { app_handle, config, fingerprint_manager, timing_config }
    }

    /// ä¿å­˜è°ƒè¯•HTMLåˆ°æ–‡ä»¶ï¼ˆä»…åœ¨ DEBUG_SAVE_HTML ä¸º true æ—¶ç”Ÿæ•ˆï¼‰
    fn save_debug_html(html: &str, prefix: &str) {
        if !DEBUG_SAVE_HTML {
            return;
        }

        let timestamp = chrono::Local::now().format("%Y%m%d_%H%M%S%.3f");
        let filename = format!("{}_{}.html", prefix, timestamp);
        let filepath = PathBuf::from(DEBUG_HTML_DIR).join(&filename);

        // ç¡®ä¿ç›®å½•å­˜åœ¨
        if let Err(e) = fs::create_dir_all(DEBUG_HTML_DIR) {
            warn!(error = %e, dir = DEBUG_HTML_DIR, "Failed to create debug HTML directory");
            return;
        }

        match fs::write(&filepath, html) {
            Ok(_) => {
                info!(
                    path = %filepath.display(),
                    bytes = html.len(),
                    "ğŸ” Debug HTML saved"
                );
            }
            Err(e) => {
                warn!(error = %e, path = %filepath.display(), "Failed to save debug HTML");
            }
        }
    }

    /// å¯¼èˆªåˆ°URLå¹¶ç­‰å¾…ï¼ˆå¸¦è¶…æ—¶ï¼‰
    async fn goto_with_timeout(
        &self,
        page: &chromiumoxide::page::Page,
        url: &str,
        stage: &str,
    ) -> Result<(), String> {
        let timeout_ms = self.config.wait_timeout_ms.max(30000);
        info!(%url, stage, timeout_ms, "Navigating with Chromium");

        // å¯¼èˆª
        page.goto(url)
            .await
            .map_err(|e| format!("Chromium goto error ({}): {}", stage, e))?;

        // ç­‰å¾…å¯¼èˆªå®Œæˆ
        let start = std::time::Instant::now();
        let timeout = Duration::from_millis(timeout_ms);

        loop {
            match page.wait_for_navigation().await {
                Ok(_) => {
                    info!(%url, stage, elapsed_ms = start.elapsed().as_millis(), "Navigation completed");
                    return Ok(());
                }
                Err(e) => {
                    if start.elapsed() >= timeout {
                        warn!(%url, stage, timeout_ms, error = %e, "Navigation timeout");
                        return Err(format!("Navigation timeout ({}): {}", stage, e));
                    }
                    // çŸ­æš‚ç­‰å¾…åé‡è¯•
                    sleep(Duration::from_millis(100)).await;
                }
            }
        }
    }

    /// æ³¨å…¥åæ£€æµ‹è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
    async fn inject_anti_detection_scripts(
        &self,
        page: &chromiumoxide::page::Page,
    ) -> Result<(), String> {
        let anti_detection_script = r#"
            // ========== 1. æ ¸å¿ƒwebdriveræ£€æµ‹ç»•è¿‡ ==========
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
                configurable: true
            });

            // åˆ é™¤å¯èƒ½å­˜åœ¨çš„è‡ªåŠ¨åŒ–æ ‡è¯†
            delete navigator.__proto__.webdriver;

            // ========== 2. Chromeå¯¹è±¡å®Œæ•´æ¨¡æ‹Ÿ ==========
            if (!window.chrome) {
                window.chrome = {};
            }

            // ========== 3. æ’ä»¶æ¨¡æ‹Ÿ ==========
            const pluginData = [
                { name: 'Chrome PDF Plugin', filename: 'internal-pdf-viewer', description: 'Portable Document Format' }
            ];
            Object.defineProperty(navigator, 'plugins', {
                get: () => {
                    const arr = Object.create(PluginArray.prototype);
                    return arr;
                },
                configurable: true
            });

            // ========== 4. languagesæ•°ç»„ ==========
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en-US', 'en'],
                configurable: true
            });

            // ========== 12. è‡ªåŠ¨åŒ–æ£€æµ‹å‡½æ•° ==========
            delete window.__playwright;
            delete window.__pw_manual;
            delete window.callPhantom;
            delete window._phantom;
            delete window.phantom;
            delete window.__nightmare;
            delete window.domAutomation;
            delete window.domAutomationController;

            console.log('[AIPP] Anti-detection scripts injected successfully');
        "#;

        page.evaluate_on_new_document(anti_detection_script)
            .await
            .map_err(|e| format!("Failed to inject anti-detection script: {}", e))?;

        info!("Anti-detection scripts injected");
        Ok(())
    }

    /// è·å–ç”¨æˆ·æ•°æ®ç›®å½•
    fn get_user_data_dir(&self) -> Result<PathBuf, String> {
        if let Some(ref custom_dir) = self.config.user_data_dir {
            Ok(PathBuf::from(custom_dir))
        } else {
            let base = self
                .app_handle
                .path()
                .app_data_dir()
                .map_err(|e| format!("Failed to get app data dir: {}", e))?;
            Ok(base.join("chromiumoxide_profile"))
        }
    }

    /// æ£€æŸ¥ä»£ç†æ˜¯å¦å¯ç”¨ï¼ˆå¿«é€ŸTCPè¿æ¥æµ‹è¯•ï¼‰
    async fn check_proxy_available(proxy_url: &str) -> Result<(), String> {
        use std::net::ToSocketAddrs;

        // è§£æä»£ç†URLè·å–ä¸»æœºå’Œç«¯å£
        let url = proxy_url.trim();
        let url =
            url.strip_prefix("http://").or_else(|| url.strip_prefix("https://")).unwrap_or(url);
        let url = url.strip_prefix("socks5://").unwrap_or(url);

        // ç§»é™¤å¯èƒ½çš„è·¯å¾„éƒ¨åˆ†
        let host_port = url.split('/').next().unwrap_or(url);

        // å°è¯•è§£æåœ°å€
        let addr = host_port
            .to_socket_addrs()
            .map_err(|e| format!("Failed to resolve proxy address '{}': {}", host_port, e))?
            .next()
            .ok_or_else(|| format!("No address found for proxy: {}", host_port))?;

        // å°è¯•TCPè¿æ¥ï¼Œè¶…æ—¶3ç§’
        let timeout = Duration::from_secs(3);
        match tokio::time::timeout(timeout, tokio::net::TcpStream::connect(addr)).await {
            Ok(Ok(_stream)) => {
                debug!(proxy = %proxy_url, "Proxy is reachable");
                Ok(())
            }
            Ok(Err(e)) => Err(format!("Failed to connect to proxy {}: {}", proxy_url, e)),
            Err(_) => {
                Err(format!("Proxy connection timeout ({}s): {}", timeout.as_secs(), proxy_url))
            }
        }
    }

    /// ä½¿ç”¨HTTPç›´æ¥è¯·æ±‚
    async fn fetch_with_http(&self, url: &str) -> Result<String, String> {
        let user_agent = self.config.user_agent.as_deref().unwrap_or(
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        );

        let mut client_builder = reqwest::Client::builder()
            .user_agent(user_agent)
            .redirect(reqwest::redirect::Policy::limited(10))
            .timeout(Duration::from_millis(self.config.wait_timeout_ms));

        if let Some(ref proxy) = self.config.proxy_server {
            let proxy = reqwest::Proxy::all(proxy)
                .map_err(|e| format!("Invalid proxy configuration: {}", e))?;
            client_builder = client_builder.proxy(proxy);
        }

        let client =
            client_builder.build().map_err(|e| format!("Failed to build HTTP client: {}", e))?;

        let resp = client
            .get(url)
            .header("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
            .header("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
            .send()
            .await
            .map_err(|e| format!("HTTP request error: {}", e))?;

        let status = resp.status();
        if !status.is_success() {
            return Err(format!("HTTP status {} when fetching {}", status.as_u16(), url));
        }

        let text = resp.text().await.map_err(|e| format!("Failed to read response body: {}", e))?;

        if text.trim().is_empty() {
            warn!(%url, status = status.as_u16(), "Empty response body");
            return Err("Empty response body".to_string());
        }

        Ok(text)
    }

    /// WebViewå…œåº•å¯¼èˆªï¼ˆä¸æå–å†…å®¹ï¼‰
    async fn fallback_webview_navigation(&self, url: &str) -> Result<String, String> {
        if let Err(e) = crate::window::ensure_hidden_search_window(self.app_handle.clone()).await {
            warn!(error = %e, "Failed to create hidden search window");
        } else if let Some(window) = self.app_handle.get_webview_window("hidden_search") {
            let _ = window.navigate(url.parse().map_err(|e| format!("Invalid URL: {}", e))?);
            tokio::time::sleep(Duration::from_secs(2)).await;
        }

        Err("All fetch strategies failed; WebView navigation attempted but no content extracted"
            .to_string())
    }

    /// ä¸»è¦çš„å†…å®¹æŠ“å–æ–¹æ³•ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒç­–ç•¥
    pub async fn fetch_content(
        &mut self,
        url: &str,
        browser_manager: &BrowserManager,
        browser_pool: Option<&BrowserPool>,
    ) -> Result<String, String> {
        info!(%url, "Starting content fetch");

        // ç­–ç•¥1: Chromiumoxideï¼ˆæœ€ä¼˜ï¼Œæ”¯æŒå¤æ‚åŠ¨æ€å†…å®¹ï¼‰
        match self
            .fetch_with_chromiumoxide(url, browser_manager, browser_pool)
            .await
        {
            Ok(html) => {
                info!(strategy = "chromiumoxide", bytes = html.len(), "Fetched content");
                return Ok(html);
            }
            Err(e) => {
                warn!(error = %e, strategy = "chromiumoxide", "Fetch attempt failed");
            }
        }

        // ç­–ç•¥2: HTTPç›´æ¥è¯·æ±‚ï¼ˆå…œåº•ï¼Œé€‚åˆé™æ€å†…å®¹ï¼‰
        match self.fetch_with_http(url).await {
            Ok(html) => {
                info!(strategy = "http", bytes = html.len(), "Fetched content");
                return Ok(html);
            }
            Err(e) => {
                warn!(error = %e, strategy = "http", "Fetch attempt failed");
            }
        }

        // ç­–ç•¥3: WebViewå…œåº•ï¼ˆä¸æå–å†…å®¹ï¼Œä»…å¯¼èˆªï¼‰
        self.fallback_webview_navigation(url).await
    }

    /// ä½¿ç”¨ChromiumoxideæŠ“å–å†…å®¹
    async fn fetch_with_chromiumoxide(
        &mut self,
        url: &str,
        browser_manager: &BrowserManager,
        browser_pool: Option<&BrowserPool>,
    ) -> Result<String, String> {
        // å¦‚æœæœ‰æµè§ˆå™¨æ± ï¼Œä½¿ç”¨æ± åŒ–é¡µé¢
        if let Some(pool) = browser_pool {
            return self.fetch_with_pooled_page(url, pool).await;
        }

        let browser_path = browser_manager.get_browser_path()?;

        let user_data_dir = self.get_user_data_dir()?;
        if let Err(e) = fs::create_dir_all(&user_data_dir) {
            warn!(error = %e, dir = ?user_data_dir, "Failed to create user_data_dir");
        }

        let stealth_args = FingerprintManager::get_stealth_launch_args();

        use chromiumoxide::BrowserConfig;

        let mut builder = BrowserConfig::builder().user_data_dir(&user_data_dir).no_sandbox();

        if !self.config.headless {
            builder = builder.with_head();
        }

        if browser_path.exists() {
            builder = builder.chrome_executable(&browser_path);
        }

        for arg in &stealth_args {
            builder = builder.arg(arg);
        }

        // å¤„ç†ä»£ç†é…ç½®
        if let Some(ref proxy) = self.config.proxy_server {
            if !proxy.trim().is_empty() {
                info!(proxy = %proxy, "Checking proxy availability for fetch");
                match Self::check_proxy_available(proxy).await {
                    Ok(_) => {
                        let proxy_arg = format!("--proxy-server={}", proxy);
                        builder = builder.arg(&proxy_arg);
                        info!(proxy = %proxy, "âœ… Proxy configured for fetch");
                    }
                    Err(e) => {
                        warn!(proxy = %proxy, error = %e, "âš ï¸ Proxy not available, continuing without proxy");
                    }
                }
            }
        }

        let config = builder
            .build()
            .map_err(|e| format!("Failed to build browser config: {}", e))?;

        let (browser, mut handler) = chromiumoxide::browser::Browser::launch(config)
            .await
            .map_err(|e| format!("Failed to launch browser: {}", e))?;

        // å¯åŠ¨äº‹ä»¶å¤„ç†å™¨
        tokio::spawn(async move {
            while let Some(event) = handler.next().await {
                trace!(?event, "Chromium event received");
            }
        });

        let page = browser
            .new_page("about:blank")
            .await
            .map_err(|e| format!("Failed to create page: {}", e))?;

        // æ³¨å…¥åæ£€æµ‹è„šæœ¬
        self.inject_anti_detection_scripts(&page).await?;

        self.goto_with_timeout(&page, url, "fetch_content").await?;

        // è·å– HTML
        let html = page
            .content()
            .await
            .map_err(|e| format!("Failed to get page content: {}", e))?;

        if html.trim().is_empty() {
            warn!(
                stage = "fetch_content",
                %url,
                bytes = html.len(),
                "Empty HTML from Chromiumoxide"
            );
            return Err("Empty HTML from Chromiumoxide".to_string());
        }

        Ok(html)
    }

    /// ä½¿ç”¨æµè§ˆå™¨æ± æŠ“å–URLå†…å®¹
    async fn fetch_with_pooled_page(
        &mut self,
        url: &str,
        pool: &BrowserPool,
    ) -> Result<String, String> {
        let mut pooled_page = pool.acquire_page().await?;
        let page = pooled_page.page();

        // æ³¨å…¥åæ£€æµ‹è„šæœ¬
        self.inject_anti_detection_scripts(page).await?;

        // å¯¼èˆªåˆ° URL
        self.goto_with_timeout(page, url, "fetch_content_pooled").await?;

        // è·å– HTML
        let html = page
            .content()
            .await
            .map_err(|e| format!("Failed to get page content: {}", e))?;

        if html.trim().is_empty() {
            warn!(
                stage = "fetch_content_pooled",
                %url,
                bytes = html.len(),
                "Empty HTML from Chromiumoxide (pooled)"
            );
            return Err("Empty HTML from Chromiumoxide (pooled)".to_string());
        }

        info!(bytes = html.len(), "Successfully fetched content (pooled)");

        // pooled_page ç¦»å¼€ä½œç”¨åŸŸæ—¶è‡ªåŠ¨å½’è¿˜åˆ°æ± ä¸­
        Ok(html)
    }

    /// ä¸ºæœç´¢è¯·æ±‚å®šåˆ¶çš„è·å–æ–¹æ³•
    pub async fn fetch_search_content(
        &mut self,
        query: &str,
        search_engine: &SearchEngine,
        browser_manager: &BrowserManager,
        browser_pool: Option<&BrowserPool>,
    ) -> Result<String, String> {
        info!(%query, engine = ?search_engine, "Starting search content fetch");

        // å¦‚æœæ˜¯ Kagi ä¸”é…ç½®äº†ä¼šè¯é“¾æ¥ï¼Œä½¿ç”¨ç›´æ¥ URL æ–¹å¼æœç´¢
        if *search_engine == SearchEngine::Kagi {
            if let Some(session_url) = self.config.kagi_session_url.clone() {
                info!("Using Kagi session URL for direct search");
                return self
                    .fetch_kagi_with_session_url(query, &session_url, browser_manager, browser_pool)
                    .await;
            }
        }

        // æš‚æ—¶æœªå®ç°æœç´¢æµç¨‹ï¼Œè¿”å›é”™è¯¯
        Err("Search flow not yet implemented".to_string())
    }

    /// ä½¿ç”¨ Kagi ä¼šè¯é“¾æ¥ç›´æ¥æœç´¢
    async fn fetch_kagi_with_session_url(
        &mut self,
        query: &str,
        session_url: &str,
        browser_manager: &BrowserManager,
        browser_pool: Option<&BrowserPool>,
    ) -> Result<String, String> {
        // æ„é€ æœç´¢ URLï¼šåœ¨ä¼šè¯é“¾æ¥åé¢æ‹¼æ¥ &q=æœç´¢è¯
        let encoded_query = urlencoding::encode(query);
        let search_url = if session_url.contains('?') {
            format!("{}&q={}", session_url, encoded_query)
        } else {
            format!("{}?q={}", session_url, encoded_query)
        };

        info!(%search_url, "Fetching Kagi search results with session URL");

        // ä½¿ç”¨Chromiumoxideç›´æ¥è®¿é—®æœç´¢ç»“æœé¡µé¢
        let browser_path = browser_manager.get_browser_path()?;

        let user_data_dir = self.get_user_data_dir()?;
        if let Err(e) = fs::create_dir_all(&user_data_dir) {
            warn!(error = %e, dir = ?user_data_dir, "Failed to create user_data_dir");
        }

        let stealth_args = FingerprintManager::get_stealth_launch_args();

        use chromiumoxide::BrowserConfig;

        let mut builder = BrowserConfig::builder().user_data_dir(&user_data_dir).no_sandbox();

        if !self.config.headless {
            builder = builder.with_head();
        }

        if browser_path.exists() {
            builder = builder.chrome_executable(&browser_path);
        }

        for arg in &stealth_args {
            builder = builder.arg(arg);
        }

        // å¤„ç†ä»£ç†é…ç½®
        if let Some(ref proxy) = self.config.proxy_server {
            if !proxy.trim().is_empty() {
                info!(proxy = %proxy, "Checking proxy availability for Kagi search");
                match Self::check_proxy_available(proxy).await {
                    Ok(_) => {
                        let proxy_arg = format!("--proxy-server={}", proxy);
                        builder = builder.arg(&proxy_arg);
                        info!(proxy = %proxy, "âœ… Proxy configured for Kagi search");
                    }
                    Err(e) => {
                        warn!(proxy = %proxy, error = %e, "âš ï¸ Proxy not available, continuing without proxy");
                    }
                }
            }
        }

        let config = builder
            .build()
            .map_err(|e| format!("Failed to build browser config: {}", e))?;

        let (browser, mut handler) = chromiumoxide::browser::Browser::launch(config)
            .await
            .map_err(|e| format!("Failed to launch browser: {}", e))?;

        // å¯åŠ¨äº‹ä»¶å¤„ç†å™¨
        tokio::spawn(async move {
            while let Some(event) = handler.next().await {
                trace!(?event, "Chromium event received");
            }
        });

        let page = browser
            .new_page("about:blank")
            .await
            .map_err(|e| format!("Failed to create page: {}", e))?;

        // æ³¨å…¥åæ£€æµ‹è„šæœ¬
        self.inject_anti_detection_scripts(&page).await?;

        // ç›´æ¥å¯¼èˆªåˆ°æœç´¢ç»“æœé¡µé¢
        self.goto_with_timeout(&page, &search_url, "kagi_session_search").await?;

        // æå– HTML
        let html = page
            .content()
            .await
            .map_err(|e| format!("Failed to get page content: {}", e))?;

        if html.trim().is_empty() {
            warn!(
                stage = "kagi_session_search",
                %search_url,
                bytes = html.len(),
                "Empty HTML from Kagi session URL search"
            );
            return Err("Empty HTML from Kagi session URL search".to_string());
        }

        info!(bytes = html.len(), "Successfully fetched Kagi search results");

        // ä¿å­˜è°ƒè¯•HTML
        Self::save_debug_html(&html, "kagi_session_search");

        Ok(html)
    }
}
